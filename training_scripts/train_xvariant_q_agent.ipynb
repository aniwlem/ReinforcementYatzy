{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Do be able to import reinforcement_yatzy\n",
    "lib_path = os.path.abspath('..')\n",
    "if lib_path not in sys.path:\n",
    "    sys.path.append(lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from reinforcement_yatzy.nn_models.autoencoders.pca_encoder import PCAEncoder\n",
    "from reinforcement_yatzy.reinforcement_agents.q_agent import DeepQYatzyPlayer\n",
    "from reinforcement_yatzy.nn_models.xvariant_mlp import DiceSelector, EntrySelector, InvariantPoolingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreboard_dataset_path = os.path.join('..', 'datasets', '1_million_scoreboards.csv')\n",
    "pca_encoder = PCAEncoder(\n",
    "    pd.read_csv(scoreboard_dataset_path),\n",
    "    n_components=5\n",
    ")\n",
    " \n",
    "dice_model = DiceSelector(\n",
    "        n_dice=DeepQYatzyPlayer.NUM_DICE,\n",
    "        dice_embed_dim=5,\n",
    "        mlp_channels=[32, 16, 8, 4],\n",
    "        scoreboard_encoder=pca_encoder,\n",
    ")\n",
    "entry_model = EntrySelector(\n",
    "        n_dice = DeepQYatzyPlayer.NUM_DICE,\n",
    "        n_entries = DeepQYatzyPlayer.NUM_ENTRIES,\n",
    "        dice_pre_mlp_channels = [5, 5],\n",
    "        scoreboard_encoder = pca_encoder,\n",
    "        mlp_dims = [64, 32, 16, 8, 4],\n",
    ")\n",
    "\n",
    "agent = DeepQYatzyPlayer(\n",
    "    gamma_dice=np.log(2) / 1000,\n",
    "    gamma_entries=np.log(2) / 10_000,\n",
    "    invalid_entry_factor=0.01,\n",
    "    select_dice_model=dice_model,\n",
    "    select_entry_model=entry_model,\n",
    "    dice_buffer_size=1_000,\n",
    "    entry_buffer_size=100,\n",
    "    target_change_interval=1_000,\n",
    "    batch_size=32,\n",
    "    penalty_scratch=-30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 - Score: 2.507\n",
      "Epoch 2000 - Score: 2.52\n",
      "Epoch 3000 - Score: 2.578\n",
      "Epoch 4000 - Score: 2.451\n",
      "Epoch 5000 - Score: 2.504\n",
      "Epoch 6000 - Score: 2.531\n",
      "Epoch 7000 - Score: 2.48\n",
      "Epoch 8000 - Score: 2.469\n",
      "Epoch 9000 - Score: 2.536\n",
      "Epoch 10000 - Score: 2.605\n",
      "Epoch 11000 - Score: 2.516\n",
      "Epoch 12000 - Score: 2.536\n",
      "Epoch 13000 - Score: 2.643\n",
      "Epoch 14000 - Score: 2.592\n",
      "Epoch 15000 - Score: 2.556\n",
      "Epoch 16000 - Score: 2.586\n",
      "Epoch 17000 - Score: 2.632\n",
      "Epoch 18000 - Score: 2.548\n",
      "Epoch 19000 - Score: 2.614\n",
      "Epoch 20000 - Score: 2.648\n",
      "Epoch 21000 - Score: 2.607\n",
      "Epoch 22000 - Score: 2.706\n",
      "Epoch 23000 - Score: 2.655\n",
      "Epoch 24000 - Score: 2.688\n",
      "Epoch 25000 - Score: 2.701\n",
      "Epoch 26000 - Score: 2.654\n",
      "Epoch 27000 - Score: 2.577\n",
      "Epoch 28000 - Score: 2.631\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([n_games])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_games):\n\u001b[0;32m----> 6\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     scores[epoch] \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_total_score()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m print_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/ReinforcementYatzy/reinforcement_yatzy/reinforcement_agents/q_agent.py:383\u001b[0m, in \u001b[0;36mplay_game\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m torch.tensor(old_dice, dtype=torch.float32),\n\u001b[1;32m    382\u001b[0m torch.tensor(old_scoreboard, dtype=torch.float32),\n\u001b[0;32m--> 383\u001b[0m torch.tensor(new_scoreboard, dtype=torch.float32),\n\u001b[1;32m    384\u001b[0m i_next_entry,\n\u001b[1;32m    385\u001b[0m current_point,\n",
      "File \u001b[0;32m~/Projects/ReinforcementYatzy/reinforcement_yatzy/yatzy/base_player.py:182\u001b[0m, in \u001b[0;36mABCYatzyPlayer.play_game\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_scoreboard()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNUM_ENTRIES):\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay_turn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ReinforcementYatzy/reinforcement_yatzy/reinforcement_agents/q_agent.py:320\u001b[0m, in \u001b[0;36mplay_turn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \n\u001b[1;32m    319\u001b[0m     def play_turn(self):\n\u001b[0;32m--> 320\u001b[0m         '''\n\u001b[1;32m    321\u001b[0m         Plays a single turn, i.e. three dice throws. Stores dice and scoreboard\n\u001b[1;32m    322\u001b[0m         states, for each throw into dice_buffer, and for the last throw into the \n",
      "File \u001b[0;32m~/Projects/ReinforcementYatzy/reinforcement_yatzy/reinforcement_agents/q_agent.py:127\u001b[0m, in \u001b[0;36mselect_dice_to_throw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m curr_entries = torch.tensor(\n\u001b[1;32m    126\u001b[0m     self.scoreboard, dtype=torch.float32\n\u001b[0;32m--> 127\u001b[0m ).unsqueeze(0)\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m curr_throws_left = torch.tensor(\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ReinforcementYatzy/reinforcement_yatzy/nn_models/xvariant_mlp/selection_models/dice_selector.py:102\u001b[0m, in \u001b[0;36mDiceSelector.forward\u001b[0;34m(self, dices, scoreboards, throw_indices)\u001b[0m\n\u001b[1;32m     90\u001b[0m batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[1;32m     91\u001b[0m     dice_embeds,\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# add n_dice dimension and repeat along it\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m ],\n\u001b[1;32m     99\u001b[0m     dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    101\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add channel dim\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m mlped_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Now the results have shape [batch_size, n_channels, n_dice, n_embeds]\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# since the model only needs one value per dice the 1:st and 3:rd dimensions\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# must be pooled over.  NOTE: Could use NN instead, why not?\u001b[39;00m\n\u001b[1;32m    107\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection_pool(mlped_batch)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ReinforcementYatzy/reinforcement_yatzy/nn_models/xvariant_mlp/base_models/equivariant_mlp.py:36\u001b[0m, in \u001b[0;36mEquivariantMLP.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp:\n\u001b[0;32m---> 36\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ReinforcementYatzy/reinforcement_yatzy/nn_models/xvariant_mlp/base_models/equivariant_layer.py:52\u001b[0m, in \u001b[0;36mEquivariantLayer.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# To multiply 1:st dim with matrix\u001b[39;00m\n\u001b[1;32m     51\u001b[0m prop_reshape_batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mpermute([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 52\u001b[0m prop_term \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mprop_reshape_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambda_\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Want to pool over the set elements, permute to get them last, reshape\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# to get correct number of dims for 1dpooling\u001b[39;00m\n\u001b[1;32m     56\u001b[0m common_reshape_batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mpermute([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape([\n\u001b[1;32m     57\u001b[0m     batch_size \u001b[38;5;241m*\u001b[39m input_channels \u001b[38;5;241m*\u001b[39m embed_dim, n_elems\n\u001b[1;32m     58\u001b[0m ])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_games = 100_000\n",
    "print_interval = 1_000\n",
    "\n",
    "scores = np.zeros([n_games])\n",
    "for epoch in range(n_games):\n",
    "    agent.play_game()\n",
    "    scores[epoch] = agent.get_total_score()\n",
    "\n",
    "    if epoch != 0 and epoch % print_interval == 0:\n",
    "        print(f'Epoch {epoch} - Score: {np.mean(scores[epoch-print_interval : epoch])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
